{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender biases in Wikipedia \n",
    "## todo: find fancy title\n",
    "\n",
    "Wikipedia has become a very large source of information. By November 2019, the number of entries in the English Wikipedia is above 5M [[1]](https://en.wikipedia.org/wiki/Wikipedia:Statistics#Page_views) and keeps increasing everyday at a rate of 500 entries in averge. \n",
    "\n",
    "In previous studies Wagner et al [[2]](https://arxiv.org/abs/1501.06307) shown how gender biases manifest in Wikipedia in the way women and men are portrayed. In other studies, Graells-Garrido et al [[3]](https://labtomarket.files.wordpress.com/2018/01/wiki_gender_bias.pdf) shown that women biographies are more likely to contain sex-related content. Along with these studies, several others have studied topic-related biases in the way women are portrayed but we can also take a look from the linguistic perspective. \n",
    "\n",
    "Linguistic biases is defined as a systematic asymmetry in word choice that reflects the social-category cognitions that are applied to the described group or individual(s) [[4]](https://oxfordre.com/communication/communication/view/10.1093/acrefore/9780190228613.001.0001/acrefore-9780190228613-e-439). We want to analyze how men and women are protrayed and more specifically, the adjectives used to describe them with the aim to spot possible gender biases from a linguistic perspective. To do so, we will use the overview of the biographies in the English Wikipedia together with other characteristics of the people we are analysing.\n",
    "\n",
    "Initially we will start by exploring the dataset, i.e. ratio of male and female entries, presence of other genders, etc. Later, we will explore the language used on the overviews by focusing on the adjectives. We restrict the analysis to adjectives given the level of abstraction they provide [[5]](https://www.aaai.org/ocs/index.php/ICWSM/ICWSM15/paper/download/10539/10513). This analysis will be conducted by first extracting the most frequent adjectives from all the biographies used. We will build a vocabulary based on the most frequent adjectives used in male biographies and the most frequent ones used in female biographies. Using this vocabulary, we will create a representation of each character based on the adjectives in our vocabulary that appear in its biography. \n",
    "\n",
    "Once we have a vectorial representation of each person, we will create a model using logistic regression that will try to predict if a biography belongs to a male or female. If this task becomes feasible, it means there is a pattern in the usage of language that allows us to make a distinction between genders, highlighting the presence of a bias. Will our model succeed in its tasks? Continue with us to discover our results! \n",
    "\n",
    "[[1] Wikipedia Statistics](https://en.wikipedia.org/wiki/Wikipedia:Statistics#Page_views)\n",
    "\n",
    "[[2] It's a Man's Wikipedia? Assessing Gender Inequality in an Online Encyclopedia](https://arxiv.org/abs/1501.06307)\n",
    "\n",
    "[[3] First Women, Second Sex: Gender Bias in Wikipedia](https://labtomarket.files.wordpress.com/2018/01/wiki_gender_bias.pdf)\n",
    "\n",
    "[[4] Oxford Research Encyclopedia](https://oxfordre.com/communication/communication/view/10.1093/acrefore/9780190228613.001.0001/acrefore-9780190228613-e-439)\n",
    "\n",
    "[[5] Linguistic Bias in Collaboratively Produced Biographies: Crowdsourcing Social Stereotypes?](https://www.aaai.org/ocs/index.php/ICWSM/ICWSM15/paper/download/10539/10513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing and extraction\n",
    "\n",
    "As stated before, we are only interested in analyze the biographies of Wikipedia, so we need to filter them. More precisely, we will use the overview of the biographies in the English Wikipedia. In order to do that, we followed these steps:\n",
    "\n",
    "1. We use the [Wikidata Human Gender Indicators (WHGI)](#http://whgi.wmflabs.org) dataset, which contains all the biography articles in all Wikipedias and it is updated weekly. From this dataset (November 2019 version), we get all the biographies that are in the English Wikipedia and that have a gender. For each entry, we get the Q-id, gender and occupation. We use this dataset because it is more updated than the Wikidata one in cluster (dated from 2017). You can see the code in [here](createDataset/1_extract_qid_wikidata.py).\n",
    "\n",
    "\n",
    "2. Then, we need to link the previous information with the Wikipedia article. For that, we need to use Wikidata dataset found in the cluster. First, we filter the entries that we obtain in the previous step and obtain the name of the entry in the English Wikipedia. You can see the code in [here](createDataset/2_extract_people_wikidata.py).\n",
    "\n",
    "\n",
    "3. Next, we have to obtain the biographies from Wikipedia dataset. To do that, we simply join the English Wikipedia dataset (also found in the cluster) with the one obtained in the previous step by the Wikipedia title, which is unique. You can see the code in [here](createDataset/3_filter_people_enwiki.py).\n",
    "\n",
    "\n",
    "4. Following, we need to extract and clear the overview of the wikipedia text. First, we find the end of the overview (which usually starts either with == or [[Category: ). Then we clear the references, comments from the editors, quotes abd withs inside parenthesis or brackets. Code in [here](createDataset/4_extract_overview_enwiki.py).\n",
    "\n",
    "\n",
    "5. Finally, as it will be shown later in the analysis, we filter the database according to gender of the people. We keep only the male and the female as the other gender represent less than 1% of the whole dataset. Code in [here](createDataset/5_filter_female_male.py). \n",
    "\n",
    "The final dataset ... \n",
    "#### ADD THE SCHEMA AND MAYBE SOME INFO ON THE LENGTH\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_PATH = \"../data/\"\n",
    "WIKI_DATA = os.path.join(LOCAL_PATH, \"overview_wikipedia.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# create the context\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# load data\n",
    "df = spark.read.json(WIKI_DATA)\n",
    "\n",
    "# explode the gender column (create multiple entries for people with a list of genders)\n",
    "df = df.withColumn(\"gender\", split(regexp_replace(regexp_replace(regexp_replace(regexp_replace(df['gender'], \\\n",
    "                                                            '\\\\[', ''), '\\\\]', ''), ' ', ''),\"'\", \"\"), \",\"))\n",
    "df = df.withColumn(\"gender\", df['gender'][0])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_counts = df.groupBy(\"gender\").agg(count(\"*\").alias(\"count\")).sort(desc(\"count\"))\n",
    "gender_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In total there are {} different genders\".format(gender_counts.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open dictionary to match id to gender name\n",
    "with open('../data/dict_genders.json') as json_file:\n",
    "    line = json_file.readline()\n",
    "    dict_genders = json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender(gender):\n",
    "    return dict_genders.get(gender, \"other\")\n",
    "\n",
    "# get the gender (male, female or other) from the id\n",
    "udf_get_gender = udf(get_gender)\n",
    "gender_counts = gender_counts.withColumn(\"gender\", udf_get_gender(\"gender\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the other genders\n",
    "gender_counts_grouped = gender_counts.groupBy(\"gender\").agg(sum(\"count\").alias(\"count\")).sort(desc(\"count\"))\n",
    "gender_counts_grouped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to pandas\n",
    "gender_counts_pd = gender_counts_grouped.toPandas()\n",
    "\n",
    "pl = gender_counts_pd.plot(kind=\"bar\", x=\"gender\", y=\"count\", figsize=(15, 7), log=True, alpha=0.5, color=\"green\")\n",
    "pl.set_xlabel(\"Gender\")\n",
    "pl.set_ylabel(\"Number of biographies (Log scale)\")\n",
    "pl.set_title(\"Number of biographies by gender\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention**: The y-axis in log-scale!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = gender_counts_pd['count'].sum()\n",
    "n_male = gender_counts_pd[gender_counts_pd['gender'] == 'male']['count'].values[0]\n",
    "n_female = gender_counts_pd[gender_counts_pd['gender'] == 'female']['count'].values[0]\n",
    "n_other = n_total - n_male - n_female\n",
    "\n",
    "print(\"{:.2f}% of the entries are male\".format(n_male/n_total*100))\n",
    "print(\"{:.2f} % of the entries are female\".format(n_female/n_total*100))\n",
    "print(\"{:.2f} % of the entries are other gender\".format(n_other/n_total*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these numbers, we decide to **drop the other genders** and continue our analysis with only female and male."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction\n",
    "Explain process of extraction of the data; combination of wikimedia and wikipedia; preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_PATH = \"../data/\"\n",
    "WIKI_DATA = os.path.join(LOCAL_PATH, \"wikipedia_male_female.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data frame\n",
    "df = spark.read.json(WIKI_DATA)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous table shows an example of the data we are working with. Each row represents the article of a given person with the following information associated:\n",
    "- Name\n",
    "- ID (wikimedia)\n",
    "- Wiki-title (wikipedia)\n",
    "- Gender\n",
    "- Ocuppation\n",
    "- Overview\n",
    "\n",
    "In the following steps we are going to explore how women are represented in wikipedia. First, we will start with some basic statistics like the fraction of entries that correspond to each gender and how this varies along different occupations. After, we will enter in the core analysis of the project by analysing the language used to present the different characters. The idea is to focus on the adjectives used in the overviews and look for a bias between male and female representations. \n",
    "**ADD SOME MORE DETAILS AND INTRODUCTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data translation\n",
    "Translate wikimedia codes to the actual meaning in terms of gender and occupation.\n",
    "**Note:** Since we are interested in both gender and occupation, when the translation from wikimedia code to words is perform those people without associated occupation will be dropped from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Gender dictionary\n",
    "with open('../data/dict_genders.json') as json_file:\n",
    "    line = json_file.readline()\n",
    "    dict_genders = json.loads(line)\n",
    "    \n",
    "# Open occupations dictionary\n",
    "dict_occupations = {}\n",
    "with open('../data/dict_occupations.json') as json_file:\n",
    "    content = json_file.readlines()\n",
    "    for line in content:\n",
    "        occ = json.loads(line)\n",
    "        dict_occupations.update(occ)\n",
    "        \n",
    "# Observation: We need dict_categories_occupations.json in the data folder\n",
    "# Open occupations categories dictionary\n",
    "with open('../data/dict_categories_occupations.json') as json_file:\n",
    "    line = json_file.readline()\n",
    "    dict_cat_occ = json.loads(line)\n",
    "\n",
    "# Create function to translate a code into a category\n",
    "def translate(mapping):\n",
    "    def translate_(col):\n",
    "        return mapping.get(col)\n",
    "    return udf(translate_, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate gender and occupations codes into corresponding labels\n",
    "df = df.withColumn('gender', translate(dict_genders)('gender'))\\\n",
    "       .withColumn('occupation', explode(split(regexp_replace(regexp_replace(regexp_replace\\\n",
    "                                (regexp_replace(df['occupation'], '\\\\[', ''), '\\\\]', ''), ' ', ''),\"'\", \"\"), \",\")))\\\n",
    "       .filter(col('occupation') != '')\\\n",
    "       .withColumn('occupation', translate(dict_occupations)('occupation'))\\\n",
    "       .withColumn('field', translate(dict_cat_occ)('occupation'))\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: solve display of table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to know how many males and females are in the data frame\n",
    "# Observation: When occupation translation is done, the observations without a label are dropped, that's why, there are less male and female\n",
    "df.registerTempTable(\"df\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT gender, count(DISTINCT id) as count\n",
    "FROM df\n",
    "GROUP BY gender\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "gender_counts = spark.sql(query)\n",
    "gender_counts = gender_counts.toPandas()\n",
    "gender_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = gender_counts.plot(kind=\"bar\", x=\"gender\", y=\"count\", figsize=(15, 7), log=False, \\\n",
    "                        alpha=0.5, color=\"green\", rot=0)\n",
    "pl.set_xlabel(\"Gender\")\n",
    "pl.set_ylabel(\"Number of biographies\")\n",
    "pl.set_title(\"Number of biographies by gender\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occupation distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.registerTempTable(\"df\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT field, count(DISTINCT id) as count\n",
    "FROM df\n",
    "WHERE field IS NOT NULL\n",
    "GROUP BY field\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "occu_cat_counts = spark.sql(query)\n",
    "occu_cat_counts = occu_cat_counts.toPandas()\n",
    "occu_cat_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = occu_cat_counts.plot(kind=\"bar\", x=\"field\", y=\"count\", figsize=(15, 7), log=False, \\\n",
    "                          alpha=0.5, color=\"green\", rot=0)\n",
    "pl.set_xlabel(\"Field of occupation\")\n",
    "pl.set_ylabel(\"Number of biographies\")\n",
    "pl.set_title(\"Number of biographies by field of occupation\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common occupation among our characters is **Sports** followed by **Artist** and **Politics**. The group **None** represents all those occupations that did not match any of the previous groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = occu_cat_counts['count'].sum()\n",
    "n_sports = occu_cat_counts[occu_cat_counts['field'] == 'Sports']['count'].values[0]\n",
    "n_artist = occu_cat_counts[occu_cat_counts['field'] == 'Artist']['count'].values[0]\n",
    "n_politics = occu_cat_counts[occu_cat_counts['field'] == 'Politics']['count'].values[0]\n",
    "\n",
    "print(\"{:.2f}% of the entries work in the sports field\".format(n_sports/n_total*100))\n",
    "print(\"{:.2f}% of the entries work in the artistic field\".format(n_artist/n_total*100))\n",
    "print(\"{:.2f}% of the entries work in the politics field\".format(n_politics/n_total*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender by occupation\n",
    "\n",
    "How are the distinct genders represented within the different occupational groups? Is there any group where women have a greater representation than men?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.registerTempTable(\"df\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT field, gender, count(DISTINCT id) as count\n",
    "FROM df\n",
    "WHERE field IS NOT NULL\n",
    "GROUP BY field, gender\n",
    "ORDER BY field, gender\n",
    "\"\"\"\n",
    "\n",
    "occu_gender_counts = spark.sql(query)\n",
    "occu_gender_counts = occu_gender_counts.toPandas()\n",
    "occu_gender_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can point out different details: \n",
    "- Female biographies are less in all fields except **Model** which is associated to the mode industry. In this case, for each 5 biographies related to female characters we have one male biography.\n",
    "- **Religion** and **Military** are the groups where the ratio female:male becomes larger. In religion related biographies for each female we will find 69 males. In military related ones, for each female we will find 62 males.\n",
    "- The most balanced occupational field is **Artist** where the ratio female:male is of 1:3\"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_count = occu_gender_counts[occu_gender_counts['gender'] == 'male']['count'].tolist()\n",
    "female_count = occu_gender_counts[occu_gender_counts['gender'] == 'female']['count'].tolist()\n",
    "index = occu_gender_counts['field'].unique().tolist()\n",
    "occ_by_gender = pd.DataFrame({'male': male_count, 'female': female_count}, index=index)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(15, 14))\n",
    "pl = occ_by_gender.plot(kind=\"bar\", log=False, alpha=0.5, color=[\"green\", \"red\"], rot=0, ax=ax[0])\n",
    "pl.set_xlabel(\"Field of occupation\")\n",
    "pl.set_ylabel(\"Number of biographies\")\n",
    "pl.set_title(\"Number of biographies by gender and field of occupation\");\n",
    "             \n",
    "occ_by_gender['ratio'] = occ_by_gender.apply(lambda x: x.male / x.female, axis=1)\n",
    "pl = occ_by_gender.plot(kind=\"bar\", y='ratio', alpha=0.5, color='green', rot=0, ax=ax[1])\n",
    "for p in ax[1].patches:\n",
    "    disp= '{:.1f}'.format(p.get_height())\n",
    "    ax[1].annotate(disp, (p.get_x() * 1.005, p.get_height() +0.5))\n",
    "pl.set_xlabel(\"Field of occupation\")\n",
    "pl.set_ylabel(\"Number of biographies\")\n",
    "pl.set_title(\"Ratio of female:male biographies by field of occupation\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADJ_MALE = os.path.join(LOCAL_PATH, \"count_male_adjectives.json\")\n",
    "ADJ_FEM = os.path.join(LOCAL_PATH, \"count_female_adjectives.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_adj_male = spark.read.json(ADJ_MALE)\n",
    "most_common_adj_fem = spark.read.json(ADJ_FEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_adj_male = most_common_adj_male.orderBy(desc(\"count\"))\n",
    "most_common_adj_male_pd = most_common_adj_male.toPandas()\n",
    "first_100_adj_male = most_common_adj_male_pd[:100].copy()\n",
    "first_100_adj_male.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_adj_fem = most_common_adj_fem.orderBy(desc(\"count\"))\n",
    "most_common_adj_fem_pd = most_common_adj_fem.toPandas()\n",
    "first_100_adj_fem = most_common_adj_fem_pd[:100].copy()\n",
    "first_100_adj_fem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_adj = set()\n",
    "most_common_adj.update(first_100_adj_male['adjectives'].tolist())\n",
    "most_common_adj.update(first_100_adj_fem['adjectives'].tolist())\n",
    "most_common_adj = list(most_common_adj)\n",
    "len(most_common_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIKI_MALE = os.path.join(LOCAL_PATH, \"wikipedia_male_adjectives.json\")\n",
    "WIKI_FEM = os.path.join(LOCAL_PATH, \"wikipedia_female_adjectives.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male = spark.read.json(WIKI_MALE)\n",
    "df_fem = spark.read.json(WIKI_FEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_adjs(list_adj):\n",
    "    return len(list_adj)\n",
    "\n",
    "udf_get_n_adjs = udf(get_n_adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male_model = df_male.select(\"id\", \"gender\", \"adjectives\")\n",
    "df_male_model = df_male_model.withColumn(\"n-adjs\", udf_get_n_adjs(\"adjectives\"))\n",
    "df_male_model = df_male_model.withColumn(\"gender\", udf_get_gender(\"gender\"))\n",
    "df_male_model.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fem_model = df_fem.select(\"id\", \"gender\", \"adjectives\")\n",
    "df_fem_model = df_fem_model.withColumn(\"n-adjs\", udf_get_n_adjs(\"adjectives\"))\n",
    "df_fem_model = df_fem_model.withColumn(\"gender\", udf_get_gender(\"gender\"))\n",
    "df_fem_model.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male_pd = df_male_model.toPandas()\n",
    "df_fem_pd = df_fem_model.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input(list_words_present, list_adj_to_encode):\n",
    "    encoding = np.zeros(len(list_adj_to_encode))\n",
    "    for i, adj in enumerate(list_adj_to_encode):\n",
    "        if adj in list_words_present:\n",
    "            encoding[i] = 1\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_output(gender):\n",
    "    return int(gender == 'female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male_pd['input'] = df_male_pd.adjectives.map(lambda x: encode_input(x, most_common_adj))\n",
    "df_male_pd['output'] = df_male_pd.gender.map(lambda x: encode_output(x))\n",
    "df_male_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fem_pd['input'] = df_fem_pd.adjectives.map(lambda x: encode_input(x, most_common_adj))\n",
    "df_fem_pd['output'] = df_fem_pd.gender.map(lambda x: encode_output(x))\n",
    "df_fem_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_male = len(df_male_pd)\n",
    "n_fem = len(df_fem_pd)\n",
    "assert n_male > n_fem\n",
    "\n",
    "n_train = np.round(0.7 * n_fem).astype(np.uint)\n",
    "print(\"Number of entries for each gender on train: {}\".format(n_train))\n",
    "\n",
    "n_test = (n_fem - n_train).astype(np.uint)\n",
    "print(\"Number of entries for each gender on test: {}\".format(n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8)\n",
    "\n",
    "train_indices_fem = np.random.choice(range(n_fem), n_train, replace=False)\n",
    "test_indices_fem = np.setdiff1d(range(n_fem), train_indices_fem)\n",
    "\n",
    "train_indices_male = np.random.choice(range(n_male), n_train, replace=False)\n",
    "left_indices_male = np.setdiff1d(range(n_male), train_indices_male)\n",
    "test_indices_male = np.random.choice(left_indices_male, n_test, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_indices_fem) == len(train_indices_male)\n",
    "assert len(test_indices_fem) == len(test_indices_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fem_train = df_fem_pd.iloc[train_indices_fem]\n",
    "df_male_train = df_male_pd.iloc[train_indices_male]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fem = np.stack(df_fem_train.input)\n",
    "y_train_fem = np.stack(df_fem_train.output)\n",
    "\n",
    "X_train_male = np.stack(df_male_train.input)\n",
    "y_train_male = np.stack(df_male_train.output)\n",
    "\n",
    "X_train = np.concatenate((X_train_fem, X_train_male), axis=0)\n",
    "y_train = np.concatenate((y_train_fem, y_train_male), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of train input: {}\".format(X_train.shape))\n",
    "print(\"Shape of train output: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "# train the model\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fem_test = df_fem_pd.iloc[test_indices_fem]\n",
    "df_male_test = df_male_pd.iloc[test_indices_male]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_fem = np.stack(df_fem_test.input)\n",
    "y_test_fem = np.stack(df_fem_test.output)\n",
    "\n",
    "X_test_male = np.stack(df_male_train.input)\n",
    "y_test_male = np.stack(df_male_train.output)\n",
    "\n",
    "X_test = np.concatenate((X_test_fem, X_test_male), axis=0)\n",
    "y_test = np.concatenate((y_test_fem, y_test_male), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix (true - rows, pred - cols)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities\n",
    "probs = lr.predict_proba(X_test)\n",
    "probs_pd = pd.DataFrame(probs, columns=['prob_male', 'prob_female'])\n",
    "probs_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coefficients\n",
    "lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas DataFrame \n",
    "data_pd = {'adjective': most_common_adj, 'coefficient': lr.coef_[0].tolist()}   \n",
    "df_coef = pd.DataFrame(data_pd) \n",
    "df_coef = df_coef.sort_values(by='coefficient', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectivity_dictionary = {}\n",
    "    \n",
    "with open('../data/subjectivity_dictionary.json', 'r') as json_file:\n",
    "    for item in eval(json_file.readline()):\n",
    "        subjectivity_dictionary.update({item['word']: (item['strength'], item['subj'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjectivity(adj):\n",
    "    return subjectivity_dictionary.get(adj)[1]\n",
    "\n",
    "def get_strength(adj):\n",
    "    return subjectivity_dictionary.get(adj)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef['subjectivity'] = df_coef['adjective'].map(lambda x: get_subjectivity(x))\n",
    "df_coef['strength'] = df_coef['adjective'].map(lambda x: get_strength(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef.tail(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
