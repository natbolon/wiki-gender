{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linguistic gender biases in Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Data preprocesing and extraction](#Data-preprocessing-and-extraction)\n",
    "3. [Imports](#Imports) \n",
    "    1. [Libraries](#Libraries)\n",
    "    2. [Dictionaries](#Dictionaries)\n",
    "4. [Gender exploration](#Gender-exploration)\n",
    "5. [Data exploration](#Data-exploration)\n",
    "    1. [Gender distribution](#Gender-distribution)\n",
    "    2. [Occupation distribution](#Occupation-distribution)\n",
    "    3. [Gender by occupation](#Gender-by-occupation)\n",
    "    4. [Distribution of the overview's length](#Distribution-of-the-overview's-length)\n",
    "    5. [Distribution of the percentage of adjectives in an overview](#Distribution-of-the-percentage-of-adjectives-in-an-overview)\n",
    "    6. [Number of adjectives in an overview](#Number-of-adjectives-in-an-overview)\n",
    "7. [Adjectives analysis](#Adjectives-analysis)\n",
    "    1. [Associate subjectivity level and strength to each adjective](#Associate-subjectivity-level-and-strength-to-each-adjective)\n",
    "    2. [Word cloud for the most common adjectives](#Word-cloud-for-the-most-common-adjectives)\n",
    "    3. [Usage of strongly subjective adjectives depending on the gender](#Usage-of-strongly-subjective-adjectives-depending-on-the-gender)\n",
    "8. [Model](#Model)\n",
    "9. [Next steps](#Next-steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Wikipedia has become a very large source of information. By November 2019, the number of entries in the English Wikipedia was above 5M [[1]](https://en.wikipedia.org/wiki/Wikipedia:Statistics#Page_views) and it was increasing everyday at a rate of 500 entries in averge. \n",
    "\n",
    "In previous studies Wagner et al [[2]](https://arxiv.org/abs/1501.06307) showed how gender biases manifest in Wikipedia in the way women and men are portrayed. In a different study, Graells-Garrido et al [[3]](https://labtomarket.files.wordpress.com/2018/01/wiki_gender_bias.pdf) showed that women biographies are more likely to contain sex-related content. Along with these studies, several others have studied topic-related biases in the way women are portrayed but we can also take a look from the linguistic perspective. \n",
    "\n",
    "Linguistic biases is defined as a systematic asymmetry in word choice that reflects the social-category cognitions that are applied to the described group or individual(s) [[4]](https://oxfordre.com/communication/communication/view/10.1093/acrefore/9780190228613.001.0001/acrefore-9780190228613-e-439). We want to analyze how men and women are protrayed and more specifically, the adjectives used to describe them with the aim to spot possible biases from a linguistic perspective. To do so, we will use the overview of the biographies in the English Wikipedia together with other characteristics of the people we are analysing.\n",
    "\n",
    "Initially we will start by exploring the dataset, i.e. ratio of male and female entries, presence of other genders, etc. Later, we will explore the language used on the overviews by focusing on the adjectives. We restrict the analysis to adjectives given the level of abstraction they provide [[5]](https://www.aaai.org/ocs/index.php/ICWSM/ICWSM15/paper/download/10539/10513). This analysis will be conducted by first extracting the most frequent adjectives from all the biographies used. With them we will build a vocabulary and use it to create a representation of each character based on the adjectives in our vocabulary that appear in its biography. \n",
    "\n",
    "Once we have a vectorial representation of each person, we will create a model using logistic regression that will try to predict if a biography belongs to a male or female. If this task becomes feasible, it means there is a pattern in the usage of language that allows us to make a distinction between genders, highlighting the presence of a bias. Will our model succeed in its tasks? Continue with us to discover our results! \n",
    "\n",
    "[[1] Wikipedia Statistics](https://en.wikipedia.org/wiki/Wikipedia:Statistics#Page_views)\n",
    "\n",
    "[[2] It's a Man's Wikipedia? Assessing Gender Inequality in an Online Encyclopedia](https://arxiv.org/abs/1501.06307)\n",
    "\n",
    "[[3] First Women, Second Sex: Gender Bias in Wikipedia](https://labtomarket.files.wordpress.com/2018/01/wiki_gender_bias.pdf)\n",
    "\n",
    "[[4] Oxford Research Encyclopedia](https://oxfordre.com/communication/communication/view/10.1093/acrefore/9780190228613.001.0001/acrefore-9780190228613-e-439)\n",
    "\n",
    "[[5] Linguistic Bias in Collaboratively Produced Biographies: Crowdsourcing Social Stereotypes?](https://www.aaai.org/ocs/index.php/ICWSM/ICWSM15/paper/download/10539/10513)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing and extraction\n",
    "\n",
    "As stated before, we are only interested in analysing the biographies of the English Wikipedia, so we need to filter them. More precisely, we will use the overviews. In order to do that, we followed these steps:\n",
    "\n",
    "1. We use the [Wikidata Human Gender Indicators (WHGI)](#http://whgi.wmflabs.org) dataset, which contains all the biography articles in all Wikipedias and it is updated weekly. We use this dataset because it is more updated than the Wikidata one in cluster (dated from 2017). From this dataset (version from November the 4th, 2019 version), we get all the biographies that are in the English Wikipedia and that have a gender. For each entry, we get the Q-id (unique identifier in Wikidata), gender and occupation. Code in [here](createDataset/1_extract_qid_wikidata.py).\n",
    "\n",
    "\n",
    "2. Then, we need to link the previous information with the Wikipedia article. For that, we use the Wikidata dataset found in the cluster. First, we filter the entries that we obtained in the previous step and obtain the name of the entry in the English Wikipedia. Code in [here](createDataset/2_extract_people_wikidata.py).\n",
    "\n",
    "\n",
    "3. Next, we have to obtain the biographies from Wikipedia dataset. To do that, we simply join the English Wikipedia dataset (also found in the cluster) with the one obtained in the previous step by the Wikipedia title, which is unique. Code in [here](createDataset/3_filter_people_enwiki.py).\n",
    "\n",
    "\n",
    "4. Following, we need to extract and clear the overview of the wikipedia text. First, we find the end of the overview (which usually starts either with `==` or `[[Category:` ). Then we clear the references, comments from the editors, quotes and text inside curly brackets. Code in [here](createDataset/4_extract_overview_enwiki.py).\n",
    "\n",
    "\n",
    "5. Finally, as it will be shown later in the analysis, we filter the database according to gender of the people. We keep only the male and the female as the other genders represent less than 1% of the whole dataset. Code in [here](createDataset/5_filter_female_male.py). \n",
    "\n",
    "The final dataset contains 1,383,430 entries and it has the following schema:\n",
    "```\n",
    "root\n",
    " |-- gender: string (nullable = true)\n",
    " |-- id: string (nullable = true)\n",
    " |-- name: string (nullable = true)\n",
    " |-- occupation: string (nullable = true)\n",
    " |-- overview: string (nullable = true)\n",
    " |-- wiki-title: string (nullable = true)\n",
    "```\n",
    "\n",
    "The **gender** is represented by the its Wikidata code, the **ID** is the unique code from Wikidata, the **name** is the name of the person (not necessarily unique), the **occupation** is a list of codes from Wikidata corresponding to the occupations of one person, the **overview** is the clean introduction of Wikipedia and the **wiki-title** is the unique name from the English Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports \n",
    "\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(8)\n",
    "\n",
    "# set font size for plots\n",
    "matplotlib.rcParams.update({'font.size': 11})\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries\n",
    "\n",
    "In this section, we load the dictionaries used to tranform the codes in the dataset to the corresponding name (dict_genders and dict_occupations). We also load a dictionary to group the occupations by field and the subjectivity lexicon used to analyze the adjectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Gender dictionary\n",
    "with open('../data/dict_genders.json') as json_file:\n",
    "    line = json_file.readline()\n",
    "    dict_genders = json.loads(line)\n",
    "    \n",
    "# Open occupations dictionary\n",
    "dict_occupations = {}\n",
    "with open('../data/dict_occupations.json') as json_file:\n",
    "    content = json_file.readlines()\n",
    "    for line in content:\n",
    "        occ = json.loads(line)\n",
    "        dict_occupations.update(occ)\n",
    "        \n",
    "# Open occupations categories dictionary\n",
    "with open('../data/dict_categories_occupations.json') as json_file:\n",
    "    line = json_file.readline()\n",
    "    dict_cat_occ = json.loads(line)\n",
    "\n",
    "# Open subjectivity lexicon\n",
    "subjectivity_dictionary = {}\n",
    "with open('../data/subjectivity_dictionary.json', 'r') as json_file:\n",
    "    for item in eval(json_file.readline()):\n",
    "        subjectivity_dictionary.update({item['word']: (item['strength'], item['subj'])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender exploration\n",
    "\n",
    "In this section, we will analyze all the genders in the dataset. Here, we use the dataset extracted after step 4 from the section [data preprocessing and extraction](#Data-preprocessing-and-extraction).\n",
    "\n",
    "We find that there are 9 different genders in the dataset. However, we group them in male, female and other (because the non-binary genders have very few entries). Since the \"other\" genders represent less than 1% of the whole dataset, we decide to drop them and focus our research on male and female genders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_PATH = \"../data/\"\n",
    "WIKI_DATA = os.path.join(LOCAL_PATH, \"overview_wikipedia.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "df = spark.read.json(WIKI_DATA)\n",
    "\n",
    "# explode the gender column (create multiple entries for people with a list of genders)\n",
    "df = df.withColumn(\"gender\", split(regexp_replace(regexp_replace(regexp_replace(regexp_replace(df['gender'], \\\n",
    "                                                            '\\\\[', ''), '\\\\]', ''), ' ', ''),\"'\", \"\"), \",\"))\n",
    "df = df.withColumn(\"gender\", df['gender'][0])\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by gender and compute count\n",
    "gender_counts = df.groupBy(\"gender\").agg(count(\"*\").alias(\"count\")).sort(desc(\"count\"))\n",
    "print(\"In total there are {} different genders\".format(gender_counts.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender(gender):\n",
    "    return dict_genders.get(gender, \"other\")\n",
    "\n",
    "# get the gender (male, female or other) from the id\n",
    "udf_get_gender = udf(get_gender)\n",
    "gender_counts = gender_counts.withColumn(\"gender\", udf_get_gender(\"gender\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# group the other genders\n",
    "gender_counts_grouped = gender_counts.groupBy(\"gender\").agg(sum(\"count\").alias(\"count\")).sort(desc(\"count\"))\n",
    "gender_counts_grouped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to pandas\n",
    "gender_counts_pd = gender_counts_grouped.toPandas()\n",
    "\n",
    "pl = gender_counts_pd.plot(kind=\"bar\", x=\"gender\", y=\"count\", figsize=(10, 5), log=True, \\\n",
    "                           alpha=0.5, color=\"green\", rot=0)\n",
    "for p in pl.patches:\n",
    "    disp= '{:d}'.format(p.get_height())\n",
    "    pl.annotate(disp, (p.get_x() + 0.16, p.get_height()*1.1))\n",
    "    \n",
    "pl.set_xlabel(\"Gender\")\n",
    "pl.set_ylabel(\"Number of biographies (Log scale)\")\n",
    "pl.set_title(\"Number of biographies by gender\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention**: The y-axis is in log-scale!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = gender_counts_pd['count'].sum()\n",
    "n_male = gender_counts_pd[gender_counts_pd['gender'] == 'male']['count'].values[0]\n",
    "n_female = gender_counts_pd[gender_counts_pd['gender'] == 'female']['count'].values[0]\n",
    "n_other = n_total - n_male - n_female\n",
    "\n",
    "print(\"{:.2f}% of the entries are male\".format(n_male/n_total*100))\n",
    "print(\"{:.2f}% of the entries are female\".format(n_female/n_total*100))\n",
    "print(\"{:.2f}% of the entries are other gender\".format(n_other/n_total*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these numbers, we decide to **drop the other genders** and continue our analysis with only female and male."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "In this section, we are going to explore how women are represented in Wikipedia. First, we will start with some basic statistics like the fraction of entries that correspond to each gender and how this varies along different occupations.\n",
    "\n",
    "After, we will enter in the core analysis of the project by analysing the language used to present the different people. The idea is to focus on the adjectives used in the overviews and look for a bias between male and female representations. The length of the overview as well as the percentage of adjective in the overviews will be analyzed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIKI_DATA_FULL = os.path.join(LOCAL_PATH, \"wikipedia_male_female.json\")\n",
    "df_full = spark.read.json(WIKI_DATA_FULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to translate a code into a category\n",
    "def translate(mapping):\n",
    "    def translate_(col):\n",
    "        return mapping.get(col)\n",
    "    return udf(translate_, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate gender and occupations codes into corresponding labels\n",
    "df_full = df_full.withColumn('gender', translate(dict_genders)('gender'))\n",
    "\n",
    "# drop column 'wiki-title' to ease visualization \n",
    "df_full_viz = df_full.drop('wiki-title')\n",
    "df_full_viz.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender distribution\n",
    "\n",
    "We explore again the gender distribution, once we have dropped the other genders and we see that the dataset is very unbalanced, i.e. more than 80% of the entries are male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to know how many males and females are in the data frame\n",
    "df_full.registerTempTable(\"df_full\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT gender, count(DISTINCT id) as count\n",
    "FROM df_full\n",
    "GROUP BY gender\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "gender_counts = spark.sql(query)\n",
    "gender_counts = gender_counts.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = gender_counts_pd['count'].sum()\n",
    "n_male = gender_counts_pd[gender_counts_pd['gender'] == 'male']['count'].values[0]\n",
    "n_female = n_total - n_male\n",
    "\n",
    "print(\"{:.2f}% of the entries are male\".format(n_male/n_total*100))\n",
    "print(\"{:.2f}% of the entries are female\".format(n_female/n_total*100))\n",
    "\n",
    "pl = gender_counts.plot(kind=\"bar\", x=\"gender\", y=\"count\", figsize=(10, 5), log=False, \\\n",
    "                        alpha=0.5, color=\"green\", rot=0)\n",
    "for p in pl.patches:\n",
    "    disp= '{:d}'.format(p.get_height())\n",
    "    pl.annotate(disp, (p.get_x()+0.18, p.get_height()+ 9999))\n",
    "\n",
    "pl.set_xlabel(\"Gender\")\n",
    "pl.set_ylabel(\"Number of biographies\")\n",
    "pl.set_title(\"Number of biographies by gender\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occupation distribution\n",
    "\n",
    "We explore the most common occupations among biographies and group them into different fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full.withColumn('occupation', explode(split(regexp_replace(regexp_replace(regexp_replace\\\n",
    "                                (regexp_replace(df_full['occupation'], '\\\\[', ''), '\\\\]', ''), ' ', ''),\"'\", \"\"), \",\")))\\\n",
    "       .filter(col('occupation') != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.registerTempTable(\"df_full\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT occupation, count(DISTINCT id) as count\n",
    "FROM df_full\n",
    "GROUP BY occupation\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "occu_counts = spark.sql(query)\n",
    "occu_counts = occu_counts.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In total there are {} different occupations\".format(len(occu_counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do we deal with them?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = occu_counts['count'].sum()\n",
    "n_first_100 = occu_counts.iloc[:100]['count'].sum()\n",
    "\n",
    "print(\"The 100 most common occupations represent {:.2f}% of the all the biographies\".format(n_first_100/n_total*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_101 = occu_counts.iloc[101]['count'].sum()\n",
    "\n",
    "print(\"The 101th most common occupation represent {:.2f}% of the all the biographies\".format(n_101/n_total*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we decide to **keep only the first 100 occupations**. The other occupations represent less than 1% of the biographies, so we think they are not worth it to be analyzed in detail.\n",
    "\n",
    "For the first 100 occupations, we will group them in more general fields (e.g. screenwriter and film director will be grouped into the same category named cinema)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full.withColumn('occupation', translate(dict_occupations)('occupation'))\\\n",
    "            .withColumn('field', translate(dict_cat_occ)('occupation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.registerTempTable(\"df_full\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT field, count(DISTINCT id) as count\n",
    "FROM df_full\n",
    "WHERE field IS NOT NULL\n",
    "GROUP BY field\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "occu_cat_counts = spark.sql(query)\n",
    "occu_cat_counts = occu_cat_counts.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = occu_cat_counts.plot(kind=\"bar\", x=\"field\", y=\"count\", figsize=(15, 7), log=False, \\\n",
    "                          alpha=0.5, color=\"green\", rot=0)\n",
    "for p in pl.patches:\n",
    "    disp= '{:d}'.format(p.get_height())\n",
    "    pl.annotate(disp, (p.get_x(), p.get_height()+ 6000))\n",
    "    \n",
    "pl.set_xlabel(\"Field of occupation\")\n",
    "pl.set_ylabel(\"Number of biographies\")\n",
    "pl.set_title(\"Number of biographies by field of occupation\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common occupation among people in Wikipedia is **Sports** followed by **Artist** and **Politics**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = occu_cat_counts['count'].sum()\n",
    "n_sports = occu_cat_counts[occu_cat_counts['field'] == 'Sports']['count'].values[0]\n",
    "n_artist = occu_cat_counts[occu_cat_counts['field'] == 'Artist']['count'].values[0]\n",
    "n_politics = occu_cat_counts[occu_cat_counts['field'] == 'Politics']['count'].values[0]\n",
    "\n",
    "print(\"{:.2f}% of the entries work in the sports field\".format(n_sports/n_total*100))\n",
    "print(\"{:.2f}% of the entries work in the artistic field\".format(n_artist/n_total*100))\n",
    "print(\"{:.2f}% of the entries work in the politics field\".format(n_politics/n_total*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender by occupation\n",
    "\n",
    "How are the distinct genders represented within the different occupational groups? Is there any group where women have a greater representation than men?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.registerTempTable(\"df_full\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT field, gender, count(DISTINCT id) as count\n",
    "FROM df_full\n",
    "WHERE field IS NOT NULL\n",
    "GROUP BY field, gender\n",
    "ORDER BY field, gender\n",
    "\"\"\"\n",
    "\n",
    "occu_gender_counts = spark.sql(query)\n",
    "occu_gender_counts = occu_gender_counts.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for occupations by gender\n",
    "\n",
    "male_count = occu_gender_counts[occu_gender_counts['gender'] == 'male']['count'].tolist()\n",
    "female_count = occu_gender_counts[occu_gender_counts['gender'] == 'female']['count'].tolist()\n",
    "index = occu_gender_counts['field'].unique().tolist()\n",
    "occ_by_gender = pd.DataFrame({'male': male_count, 'female': female_count}, index=index)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 12))\n",
    "pl = occ_by_gender.plot(kind=\"bar\", log=False, alpha=0.5, color=[\"green\", \"red\"], rot=0, ax=ax[0])\n",
    "pl.set_xlabel(\"Field of occupation\")\n",
    "pl.set_ylabel(\"Number of biographies\")\n",
    "pl.set_title(\"Number of biographies by gender and field of occupation\");\n",
    "             \n",
    "occ_by_gender['ratio'] = occ_by_gender.apply(lambda x: x.male / x.female, axis=1)\n",
    "\n",
    "pl = occ_by_gender.plot(kind=\"bar\", y='ratio', alpha=0.5, color='green', rot=0, ax=ax[1])\n",
    "for p in ax[1].patches:\n",
    "    disp= '{:.1f}'.format(p.get_height())\n",
    "    ax[1].annotate(disp, (p.get_x() * 1.005, p.get_height() +0.5))\n",
    "pl.set_xlabel(\"Field of occupation\")\n",
    "pl.set_ylabel(\"Number of biographies\")\n",
    "pl.set_title(\"Ratio of female:male biographies by field of occupation\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can point out different details: \n",
    "- Female biographies are less in all fields except **Model** which is associated to the mode industry. In this case, for each 5 biographies related to female characters we have one male biography.\n",
    "- **Religion** and **Military** are the groups where the ratio female:male becomes larger. In religion related biographies for each female we will find 69 males. In military related ones, for each female we will find 62 males.\n",
    "- The most balanced occupational field is **Artist** where the ratio female:male is of 1:3\"\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of the overview's length \n",
    "There are very different biographies in the data set, some correspond to Artists, some other to Politicians. The overview's length differs significantly from biography to biography. The largest overview's length is of 23,728 words (without punctuation). The shortest overview's length is of 1. On the following plot we can observe the overview's length distribution. It seems to be a power law distribution with a higher mean than median. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(WIKI_DATA_FULL)\n",
    "\n",
    "# Remove puncutation from the feature overview\n",
    "df_overview_len = df.withColumn('overview', regexp_replace(regexp_replace(df['overview'],r'[^\\w\\s]',''), '\\s\\s+', ' '))\n",
    "\n",
    "# Tokenize feature overview\n",
    "tokenizer = Tokenizer(inputCol=\"overview\", outputCol=\"overview_tokens\")\n",
    "df_overview_len = tokenizer.transform(df_overview_len)\n",
    "\n",
    "# Compute length (number of words) of an overview\n",
    "tokens_len = udf(lambda s: len(s), IntegerType())\n",
    "df_overview_len = df_overview_len.withColumn('overview_len', tokens_len(df_overview_len['overview']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to convert a spark data frame into a pandas data frame, \n",
    "# the data frame contains the variables id and overview_len\n",
    "df_overview_len.registerTempTable(\"df_overview_len\")\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT id, overview_len\n",
    "FROM df_overview_len\n",
    "WHERE overview_len>0\n",
    "ORDER BY overview_len\n",
    "\"\"\"\n",
    "\n",
    "overview_len = spark.sql(query)\n",
    "overview_len = overview_len.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print basic statistics\n",
    "print(\"The distribution's minimum is {0:.2f}\".format(np.min(overview_len['overview_len'])))\n",
    "print(\"The distribution's maximum is {0:.2f}\".format(np.max(overview_len['overview_len'])))\n",
    "print(\"The distribution's mean    is {0:.2f}\".format(np.mean(overview_len['overview_len'])))\n",
    "print(\"The distribution's median  is {0:.2f}\".format(np.median(overview_len['overview_len'])))\n",
    "\n",
    "# Plot the distribution of overview's length\n",
    "pl_male = overview_len['overview_len'].plot(kind=\"hist\", figsize=(7, 5), log=True, alpha=0.5, color=[\"green\"], bins=20)\n",
    "pl_male.set_title('Distribution of overview\\'s length')\n",
    "pl_male.set_xlabel('Length')\n",
    "pl_male.set_ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of the percentage of adjectives in an overview\n",
    "The distributions of percentage of adjectives in an overview for Males and Females can be observed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data frames that include adjectives in each overview\n",
    "WIKI_MALE = os.path.join(LOCAL_PATH, \"wikipedia_male_adjectives.json\")\n",
    "WIKI_FEM = os.path.join(LOCAL_PATH, \"wikipedia_female_adjectives.json\")\n",
    "\n",
    "df_male = spark.read.json(WIKI_MALE)\n",
    "df_fem = spark.read.json(WIKI_FEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation and compute overview's length, adjective's length, and the percentage of adjectives per overview\n",
    "df_fem = df_fem.withColumn('overview', regexp_replace(regexp_replace(df_fem['overview'],r'[^\\w\\s]',''), '\\s\\s+', ' '))\n",
    "df_fem = df_fem.withColumn('overview_len', tokens_len(df_fem['overview']))\\\n",
    "               .withColumn('adjective_len', tokens_len(df_fem['adjectives']))\n",
    "df_fem = df_fem.withColumn('adjective_ratio_overview', df_fem['adjective_len']/df_fem['overview_len'])\n",
    "\n",
    "# Query to convert a spark data frame into a pandas data frame, the data frame contains the variables id, overview_len, adjective_len, adjective_ratio_overview\n",
    "# Define query\n",
    "df_fem.registerTempTable(\"df_fem\")\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT id, overview_len, adjective_len, adjective_ratio_overview \n",
    "FROM df_fem\n",
    "WHERE overview_len>0\n",
    "ORDER BY adjective_ratio_overview\n",
    "\"\"\"\n",
    "# Execute query\n",
    "ratio_adj_overview_fem = spark.sql(query)\n",
    "\n",
    "# Convert to pandas\n",
    "ratio_adj_overview_fem = ratio_adj_overview_fem.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation and compute overview's length, adjective's length, and the percentage of adjectives per overview\n",
    "df_male = df_male.withColumn('overview', regexp_replace(regexp_replace(df_male['overview'],r'[^\\w\\s]',''), '\\s\\s+', ' '))\n",
    "df_male = df_male.withColumn('overview_len', tokens_len(df_male['overview']))\\\n",
    "               .withColumn('adjective_len', tokens_len(df_male['adjectives']))\n",
    "df_male = df_male.withColumn('adjective_ratio_overview', df_male['adjective_len']/df_male['overview_len'])\n",
    "\n",
    "# Query to convert a spark data frame into a pandas data frame, the data frame contains the variables id, overview_len, adjective_len, adjective_ratio_overview\n",
    "# Define query\n",
    "df_male.registerTempTable(\"df_male\")\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT id, overview_len, adjective_len, adjective_ratio_overview \n",
    "FROM df_male\n",
    "WHERE overview_len>0\n",
    "ORDER BY adjective_ratio_overview\n",
    "\"\"\"\n",
    "# Execute query\n",
    "ratio_adj_overview_male = spark.sql(query)\n",
    "# Convert to pandas\n",
    "ratio_adj_overview_male = ratio_adj_overview_male.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, each overview does not present a large percentage of adjectives. The distribution for the Female gender is a power law. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print basic statistics\n",
    "print(\"DISTRIBUTION FOR FEMALE OVERVIEWS:\")\n",
    "print(\"The distribution's minimum is {0:.2f}%\".format(np.min(ratio_adj_overview_fem['adjective_ratio_overview']*100)))\n",
    "print(\"The distribution's maximum is {0:.2f}%\".format(np.max(ratio_adj_overview_fem['adjective_ratio_overview']*100)))\n",
    "print(\"The distribution's mean    is {0:.2f}%\".format(np.mean(ratio_adj_overview_fem['adjective_ratio_overview']*100)))\n",
    "print(\"The distribution's median  is {0:.2f}%\".format(np.median(ratio_adj_overview_fem['adjective_ratio_overview']*100)))\n",
    "\n",
    "print(\"\\nDISTRIBUTION FOR MALE OVERVIEWS:\")\n",
    "print(\"The distribution's minimum is {0:.2f}%\".format(np.min(ratio_adj_overview_male['adjective_ratio_overview']*100)))\n",
    "print(\"The distribution's maximum is {0:.2f}%\".format(np.max(ratio_adj_overview_male['adjective_ratio_overview']*100)))\n",
    "print(\"The distribution's mean    is {0:.2f}%\".format(np.mean(ratio_adj_overview_male['adjective_ratio_overview']*100)))\n",
    "print(\"The distribution's median  is {0:.2f}%\".format(np.median(ratio_adj_overview_male['adjective_ratio_overview']*100)))\n",
    "\n",
    "# Plot the histogram of the feature\n",
    "fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "ax[0].hist(ratio_adj_overview_male['adjective_ratio_overview'], bins = 15, color = 'green', alpha=0.5)\n",
    "ax[1].hist(ratio_adj_overview_fem['adjective_ratio_overview'], bins = 15, color = 'red', alpha=0.5)\n",
    "\n",
    "# Tunning the plot\n",
    "# Setting title, x and y labels\n",
    "ax[0].set_title('Distribution Percentage of adjectives\\n in the biography overview - Male')\n",
    "ax[0].set_xlabel('Percentage')\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[1].set_title('Distribution Percentage of adjectives\\n in the biography overview - Female')\n",
    "ax[1].set_xlabel('Percentage')\n",
    "ax[1].set_ylabel('Frequency')\n",
    "\n",
    "ax[0].set_yscale('log')\n",
    "ax[1].set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of adjectives in an overview\n",
    "\n",
    "Once we know the percentage of adjectives per overview, we analyze the number of adjectives that it represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common adjectives used in male and female overviews\n",
    "ADJ_MALE = os.path.join(LOCAL_PATH, \"count_male_adjectives.json\")\n",
    "ADJ_FEM = os.path.join(LOCAL_PATH, \"count_female_adjectives.json\")\n",
    "\n",
    "most_common_adj_male = spark.read.json(ADJ_MALE)\n",
    "most_common_adj_fem = spark.read.json(ADJ_FEM)\n",
    "\n",
    "# overviews adjectives for all characters\n",
    "WIKI_MALE = os.path.join(LOCAL_PATH, \"wikipedia_male_adjectives.json\")\n",
    "WIKI_FEM = os.path.join(LOCAL_PATH, \"wikipedia_female_adjectives.json\")\n",
    "\n",
    "df_male = spark.read.json(WIKI_MALE)\n",
    "df_fem = spark.read.json(WIKI_FEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total number of adjectives per overview\n",
    "def get_nb_adjs(list_adj):\n",
    "    return len(list_adj)\n",
    "\n",
    "udf_get_nb_adjs = udf(get_nb_adjs)\n",
    "\n",
    "df_male_totals = df_male.withColumn(\"nb-adjs\", udf_get_nb_adjs(\"adjectives\"))\n",
    "df_fem_totals = df_fem.withColumn(\"nb-adjs\", udf_get_nb_adjs(\"adjectives\"))\n",
    "\n",
    "# compute statistics\n",
    "def stats_nb_adj(df, gender):\n",
    "    count_adj = df.agg(mean(col(\"nb-adjs\")), stddev(col(\"nb-adjs\"))).collect()\n",
    "    print('{}\\t| Average num of adjectives: {:.2f} | Std of the num of adjectives: {:.2f}'.\\\n",
    "          format(gender, count_adj[0][0], count_adj[0][1]) )\n",
    "\n",
    "stats_nb_adj(df_male_totals, 'Male')\n",
    "stats_nb_adj(df_fem_totals, 'Female')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjectives analysis\n",
    "\n",
    "In this section we analyze the adjectives used to describe the different characters. We use the subjectivity lexicon version used in \"Theresa Wilson, Janyce Wiebe, and Paul Hoffmann (2005). Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis. Proc. of HLT-EMNLP-2005.\" [[1]](https://mpqa.cs.pitt.edu/lexicons/subj_lexicon/). This allows to determine the degree of subjectivity of the vocabularity and if the given adjectives are usually employed with a positive or negative connotation. \n",
    "\n",
    "First, we will start by associating each adjective with its subjectivity and strength values. We will then visualize the most common adjectives by gender and their associated degree of strength (negative, positive or neutral). Finally, we will study the usage of strongly subjective adjectives based on the gender. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associate subjectivity level and strength to each adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most frequent adjectives for each gender\n",
    "most_common_adj_male = most_common_adj_male.orderBy(desc(\"count\"))\n",
    "most_common_adj_fem = most_common_adj_fem.orderBy(desc(\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain subjectivity degree and strength of the word\n",
    "def get_subjectivity(adj):\n",
    "    return subjectivity_dictionary.get(adj)[1]\n",
    "\n",
    "def get_strength(adj):\n",
    "    return subjectivity_dictionary.get(adj)[0]\n",
    "\n",
    "udf_get_subj = udf(get_subjectivity)\n",
    "udf_get_strength = udf(get_strength)\n",
    "\n",
    "most_common_adj_male = most_common_adj_male.withColumn(\"subjectivity\", udf_get_subj(\"adjectives\"))\n",
    "most_common_adj_fem = most_common_adj_fem.withColumn(\"subjectivity\", udf_get_subj(\"adjectives\"))\n",
    "most_common_adj_male = most_common_adj_male.withColumn(\"strength\", udf_get_strength(\"adjectives\"))\n",
    "most_common_adj_fem = most_common_adj_fem.withColumn(\"strength\", udf_get_strength(\"adjectives\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show most common adjectives in each case with their subjectivity and strength\n",
    "print('\\t\\t MALE')\n",
    "most_common_adj_male.show(5)\n",
    "print('\\n\\t\\t FEMALE')\n",
    "most_common_adj_fem.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now we have obtained the most used adjectives for each gender and associate them with their degree of strength and subjectivity. If we compare the top-five adjectives of each gender, we can see there are 3 shared words: **popular**, **best** and **notable**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word cloud for the most common adjectives\n",
    "\n",
    "Visualization of the most common adjectives used in the overviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_male_dict = most_common_adj_male.select('adjectives', 'count').toPandas().set_index('adjectives').T.to_dict('records')\n",
    "adj_female_dict = most_common_adj_fem.select('adjectives', 'count').toPandas().set_index('adjectives').T.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map subjectity of words to colors\n",
    "word_to_color = dict()\n",
    "\n",
    "for word in subjectivity_dictionary:\n",
    "    if subjectivity_dictionary[word][1] == \"positive\":\n",
    "        word_to_color[word] = '#377eb8' # blue\n",
    "    if subjectivity_dictionary[word][1] == \"negative\":\n",
    "        word_to_color[word] = '#ff7f00' # orange\n",
    "    if subjectivity_dictionary[word][1] == \"neutral\":\n",
    "        word_to_color[word] = '#999999' # grey\n",
    "\n",
    "def color_func(word, *args, **kwargs):\n",
    "    try:\n",
    "        color = word_to_color[word]\n",
    "    except KeyError:\n",
    "        color = '#000000' # black\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordcloud(mask_image, adj_dict):\n",
    "    mask_ = np.array(Image.open(mask_image))\n",
    "    wc = WordCloud(background_color=\"white\", max_words=500, mask=mask_, \n",
    "               contour_width=3, contour_color='peru', color_func=color_func)\n",
    "    # generate word cloud\n",
    "    wc.generate_from_frequencies(adj_dict[0])\n",
    "    \n",
    "    return wc\n",
    "\n",
    "\n",
    "def viz_wordcloud(wc_male, wc_fem):\n",
    "    fig,ax = plt.subplots(1,2, figsize=(20,20))\n",
    "    ax[0].imshow(wc_male, cmap=plt.cm.gray, interpolation=\"bilinear\")\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[1].imshow(wc_fem, cmap=plt.cm.gray, interpolation=\"bilinear\")\n",
    "    ax[1].axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following word cloud shows the 500 most common adjectives used in male and female biographies. The size of the word is proportional to the frequency of appearance while the color represents the connotation. In <span style=\"color:#377eb8\">**blue**</span>  we see the adjectives ranked as positive, in <span style=\"color:#ff7f00\">**orange**</span>  the ones ranked negative and in <span style=\"color:#999999\">**grey**</span> the ones considered as neutral. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_male   = generate_wordcloud(\"../data/male.png\", adj_male_dict)\n",
    "wc_female = generate_wordcloud(\"../data/female.png\", adj_female_dict)\n",
    "\n",
    "viz_wordcloud(wc_male, wc_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both genders we see a higher presence of positive-related words as well as some shared adjectives as we showed in the previous subsection. Given the results of this first inspection, we will conduct further quantitative research to see the usage of positive versus negative connoted words and their degree of subjectivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage of strongly subjective adjectives depending on the gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity_strength(df):\n",
    "    \"\"\"\n",
    "    compute number of adjectives per strength and subjectivity used in the overviews\n",
    "    \"\"\"\n",
    "    # count adj per strength and subjectivity\n",
    "    overview_subjectivity = df.groupBy('strength', 'subjectivity').\\\n",
    "    agg(sum('count').alias('sum_')).orderBy(desc('sum_'))\n",
    "    \n",
    "    overview_subjectivity = overview_subjectivity.replace('', 'None')\n",
    "    \n",
    "    # compute percentage of adj in the strongly subjective category\n",
    "    strong_adj = df.where((col(\"strength\") == \"strongsubj\")).\\\n",
    "    groupBy('strength', 'subjectivity').agg({'count':'sum'}).\\\n",
    "    where((col(\"subjectivity\") == \"positive\") | (col(\"subjectivity\") == \"negative\"))\n",
    "    \n",
    "    strong_adj = strong_adj.\\\n",
    "    withColumn(\"percentage\", 100*strong_adj['sum(count)']/ df.agg({'count':'sum'}).\\\n",
    "               collect()[0][0])\n",
    "\n",
    "    return overview_subjectivity, strong_adj\n",
    "    \n",
    "# compute statistics for each gender\n",
    "os_male, strength_adj_male = subjectivity_strength(most_common_adj_male)\n",
    "os_female, strength_adj_female = subjectivity_strength(most_common_adj_fem)\n",
    "\n",
    "# show results in a single table\n",
    "os_genders = os_male.withColumnRenamed('sum_', 'male_sum').\\\n",
    "join(os_female.withColumnRenamed('sum_', 'female_sum'), ['strength', 'subjectivity'])\n",
    "\n",
    "strength_genders = strength_adj_male.withColumnRenamed('percentage', 'male_percentage').\\\n",
    "join(strength_adj_female.withColumnRenamed('percentage', 'female_percentage'), ['strength', 'subjectivity']).\\\n",
    "drop('sum(count)')\n",
    "\n",
    "# visualize\n",
    "os_genders_pd = os_genders.toPandas()\n",
    "strength_genders_pd = strength_genders.toPandas().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_st = 100*os_genders_pd.groupby('subjectivity').sum()/os_genders_pd[['female_sum','male_sum']].sum()\n",
    "percentage_st.round(2).rename(columns={'female_sum':'percentage_female', 'male_sum':'percentage_male'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_sub = 100*os_genders_pd.groupby('strength').sum()/os_genders_pd[['female_sum','male_sum']].sum()\n",
    "percentage_sub.round(2).rename(columns={'female_sum':'percentage_female', 'male_sum':'percentage_male'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strength_genders_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analysing the distribution of adjectives along the overviews, we can see the distribution of strengths and subjectivities is similar for both genders. In both cases, the usage of negative words to describe the different characters is lower than the positive ones and the adjectives used are mostly weakly subjective.\n",
    "In terms of strongly subjective words, again the positive ones are more used than the negatives and they are equally distributed for both genders.\n",
    "Given the analysis about the adjectives conducted up to now, we are still not able to distinguish if there exist a clear linguistic bias in the usage of the words. Nevertheless, the following section will introduce new insights to the discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "In this section, we build a model with the most common adjectives in the overviews of the biographies to find out if there is any bias on how males and females are described. We force to have a balanced dataset and our hypothesis is that if the accuracy obtained is higher than 0.5 there is a bias, because the model is able to learn something from the features. Therefore, if that is the case, we will analyze which adjectives create that bias from the coefficients of the model.\n",
    "\n",
    "Since the whole dataset is very unbalanced, we take the 100 most common adjectives from male and the 100 most common adjectives from female biographies, and we merge them. That gives us a total of 112 adjectives to use as features of our model. To encode these features, we create a vector of features with 1 if the adjective is present in the overview and 0 if not. The output we want to predict corresponds to the gender of the biographies. We use 0 for male and 1 for female. \n",
    "\n",
    "We train a logistic regression model and obtain an accuracy of 58.9% for the test dataset, which means that **the bias exists**. In order to know which adjectives influence more on the linguistic bias, we analyze their coefficients. The higher the coefficient, the more biased to female overviews and the lower the coefficient, the more biased to male overviews. Then, we analyze the subjectivity of these adjecitves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(df, num=100):\n",
    "    \"\"\"\n",
    "    get most common adjectives and return \n",
    "    \"\"\"\n",
    "    df = df.orderBy(desc(\"count\"))\n",
    "    df_pd = df.toPandas()\n",
    "    first_100_adj = df_pd[:num].copy()\n",
    "    return first_100_adj\n",
    "\n",
    "# get most common adjectives for male and female\n",
    "first_100_adj_male = most_common(most_common_adj_male, 100)\n",
    "first_100_adj_fem = most_common(most_common_adj_fem, 100)\n",
    "\n",
    "# create vocabulary for the model with the set of adjectives previous found\n",
    "most_common_adj = set()\n",
    "most_common_adj.update(first_100_adj_male['adjectives'].tolist())\n",
    "most_common_adj.update(first_100_adj_fem['adjectives'].tolist())\n",
    "most_common_adj = list(most_common_adj)\n",
    "print(\"Total size of vocabulary: {}\".format(len(most_common_adj)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate df for the model \n",
    "def df_model(df):\n",
    "    df_model = df.withColumn('occupation', explode(split(regexp_replace(regexp_replace(regexp_replace\\\n",
    "                                (regexp_replace(df['occupation'], '\\\\[', ''), '\\\\]', ''), ' ', ''),\\\n",
    "                                \"'\", \"\"), \",\"))).filter(col('occupation') != '').withColumn('occupation',\\\n",
    "                                translate(dict_occupations)('occupation')).withColumn('field', \\\n",
    "                                translate(dict_cat_occ)('occupation')).filter(col(\"field\") != '').\\\n",
    "                                withColumn(\"gender\", udf_get_gender(\"gender\"))\n",
    "    df_model = df_model.select(\"id\", \"gender\", \"adjectives\", \"field\").dropDuplicates()\n",
    "    return df_model\n",
    "    \n",
    "df_male_model = df_model(df_male)\n",
    "df_fem_model = df_model(df_fem)\n",
    "\n",
    "# convert to pandas\n",
    "df_male_pd = df_male_model.toPandas()\n",
    "df_fem_pd = df_fem_model.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input: kind of one-hot coding 🔥\n",
    "def encode_input(list_words_present, list_adj_to_encode):\n",
    "    encoding = np.zeros(len(list_adj_to_encode))\n",
    "    for i, adj in enumerate(list_adj_to_encode):\n",
    "        if adj in list_words_present:\n",
    "            encoding[i] = 1\n",
    "    return encoding\n",
    "\n",
    "# encode gender\n",
    "def encode_output(gender):\n",
    "    return int(gender == 'female')\n",
    "\n",
    "# apply encoder to df\n",
    "def encode_df(df):\n",
    "    df['input'] = df.adjectives.map(lambda x: encode_input(x, most_common_adj))\n",
    "    df['output'] = df.gender.map(lambda x: encode_output(x))\n",
    "    \n",
    "\n",
    "encode_df(df_male_pd)\n",
    "encode_df(df_fem_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to balance the data\n",
    "\n",
    "In order to do that, we are going to use **propensity score matching**. We are going to use only single feature which is the field of occupation. Therefore, we are going to select the same number of female and male for each field of occupation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cat_occ = np.unique(list(dict_cat_occ.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize train and test data\n",
    "X_train = np.empty((0,len(most_common_adj)))\n",
    "X_test = np.empty((0,len(most_common_adj)))\n",
    "\n",
    "y_train = np.empty((0))\n",
    "y_test = np.empty((0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_output_gender(df):\n",
    "    X = np.stack(df.input)\n",
    "    y = np.stack(df.output)\n",
    "    return X,y\n",
    "\n",
    "def get_input_output(df_fem, df_male):\n",
    "    X_fem, y_fem = get_input_output_gender(df_fem)\n",
    "    X_male, y_male = get_input_output_gender(df_male)\n",
    "    \n",
    "    X = np.concatenate((X_fem, X_male), axis=0)\n",
    "    y = np.concatenate((y_fem, y_male), axis=0)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in unique_cat_occ:\n",
    "    n_cat_fem = len(df_fem_pd[df_fem_pd['field'] == cat])\n",
    "    n_cat_male = len(df_male_pd[df_male_pd['field'] == cat])\n",
    "    n_total = np.min((n_cat_fem, n_cat_male))\n",
    "    \n",
    "    # split data in test and train\n",
    "    n_train = np.round(0.7 * n_total).astype(np.uint)\n",
    "    n_test = (n_total - n_train).astype(np.uint)\n",
    "    \n",
    "    # select entries for the train and test df\n",
    "    if n_cat_fem == n_total:\n",
    "        train_indices_fem = np.random.choice(range(n_cat_fem), n_train, replace=False)\n",
    "        test_indices_fem = np.setdiff1d(range(n_cat_fem), train_indices_fem)\n",
    "        \n",
    "        train_indices_male = np.random.choice(range(n_cat_male), n_train, replace=False)\n",
    "        left_indices_male = np.setdiff1d(range(n_cat_male), train_indices_male)\n",
    "        test_indices_male = np.random.choice(left_indices_male, n_test, replace=False)\n",
    "        \n",
    "    else: \n",
    "        train_indices_male = np.random.choice(range(n_cat_male), n_train, replace=False)\n",
    "        test_indices_male = np.setdiff1d(range(n_cat_male), train_indices_male)\n",
    "        \n",
    "        train_indices_fem = np.random.choice(range(n_cat_fem), n_train, replace=False)\n",
    "        left_indices_fem = np.setdiff1d(range(n_cat_fem), train_indices_fem)\n",
    "        test_indices_fem = np.random.choice(left_indices_fem, n_test, replace=False)\n",
    "        \n",
    "    # ensure balanced dataset\n",
    "    assert len(train_indices_fem) == len(train_indices_male)\n",
    "    assert len(test_indices_fem) == len(test_indices_male)\n",
    "    \n",
    "    # build train df\n",
    "    df_fem_cat_train = df_fem_pd[df_fem_pd['field']==cat].iloc[train_indices_fem]\n",
    "    df_male_cat_train = df_male_pd[df_male_pd['field']==cat].iloc[train_indices_male]\n",
    "\n",
    "    # build test df\n",
    "    df_fem_cat_test = df_fem_pd[df_fem_pd['field']==cat].iloc[test_indices_fem]\n",
    "    df_male_cat_test = df_male_pd[df_male_pd['field']==cat].iloc[test_indices_male]\n",
    "    \n",
    "    # get input, output from train data\n",
    "    X_train_cat, y_train_cat = get_input_output(df_fem_cat_train, df_male_cat_train)\n",
    "    # get input, output from test data\n",
    "    X_test_cat, y_test_cat = get_input_output(df_fem_cat_test, df_male_cat_test)\n",
    "    \n",
    "    X_train = np.concatenate((X_train, X_train_cat), axis=0)\n",
    "    y_train = np.concatenate((y_train, y_train_cat), axis=0)\n",
    "    \n",
    "    X_test = np.concatenate((X_test, X_test_cat), axis=0)\n",
    "    y_test = np.concatenate((y_test, y_test_cat), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of entries for each gender on train: {}\".format(int(y_train.shape[0]/2)))\n",
    "print(\"Number of entries for each gender on test: {}\".format(int(y_test.shape[0]/2)))\n",
    "\n",
    "print(\"\\nShape of train input:\\t{}\".format(X_train.shape))\n",
    "print(\"Shape of train output:\\t{}\".format(y_train.shape))\n",
    "\n",
    "print(\"\\nShape of test input:\\t{}\".format(X_test.shape))\n",
    "print(\"Shape of test output:\\t{}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# train the model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix (true - rows, pred - cols)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion Matrix:\\n')\n",
    "print('T\\P \\t male \\t female')\n",
    "print('male \\t', cm[0,0], '\\t', cm[0,1])\n",
    "print('female \\t', cm[1,0], '\\t', cm[1,1])\n",
    "print(\"\\nT - True, P - Predicted\")\n",
    "# accuracy\n",
    "print(\"\\n\\nAccuracy of the model in test dataset: {:.3f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas DataFrame with coefficients and its corresponding adjective\n",
    "data_pd = {'adjective': most_common_adj, 'coefficient': lr.coef_[0].tolist()}   \n",
    "df_coef = pd.DataFrame(data_pd) \n",
    "df_coef = df_coef.sort_values(by='coefficient', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subjectivity and strength of the adjectives\n",
    "df_coef['subjectivity'] = df_coef['adjective'].map(lambda x: get_subjectivity(x))\n",
    "df_coef['strength'] = df_coef['adjective'].map(lambda x: get_strength(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adjectives correlated to female bias:\")\n",
    "df_coef.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adjectives correlated to male bias:\")\n",
    "df_coef.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the results above, we can see the adjectives more biased for both genders. In our next steps, we plan to deeper analyze them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring adjectives representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fem_count = df_fem_model.count()\n",
    "male_count = df_male_model.count()\n",
    "\n",
    "fem_adj = df_fem_model.withColumn('adjectives', explode(df_fem_model.adjectives)).\\\n",
    "           groupBy('adjectives').count().toPandas()\n",
    "\n",
    "male_adj = df_male_model.withColumn('adjectives', explode(df_male_model.adjectives)).\\\n",
    "            groupBy('adjectives').count().toPandas()\n",
    "\n",
    "adj_presence = fem_adj.merge(male_adj, on='adjectives', suffixes=('_female','_male'))\n",
    "adj_presence['freq_female'] = 100*adj_presence['count_female']/fem_count\n",
    "adj_presence['freq_male'] = 100*adj_presence['count_male']/male_count\n",
    "adj_presence.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjective appearance in the biographies by gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_adj = 5\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "adj_presence[adj_presence.adjectives.isin(df_coef.head(num_adj)['adjective'].tolist())][['adjectives', 'count_female', 'count_male']].\\\n",
    "plot(kind='bar', x='adjectives', ax=ax[0], rot=0)\n",
    "adj_presence[adj_presence.adjectives.isin(df_coef.tail(num_adj)['adjective'].tolist())][['adjectives', 'count_female', 'count_male']].\\\n",
    "plot(kind='bar', x='adjectives', ax=ax[1], rot=0)\n",
    "\n",
    "ax[0].set_title('Higher coefficient score')\n",
    "ax[1].set_title('Lower coefficient score')\n",
    "ax[0].set_ylabel('# biographies containing the adjective')\n",
    "ax[1].set_ylabel('# biographies containing the adjective')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_adj = 5\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "adj_presence[adj_presence.adjectives.isin(df_coef.head(num_adj)['adjective'].tolist())][['adjectives', 'freq_female', 'freq_male']].\\\n",
    "plot(kind='bar', x='adjectives', ax=ax[0], rot=0)\n",
    "adj_presence[adj_presence.adjectives.isin(df_coef.tail(num_adj)['adjective'].tolist())][['adjectives', 'freq_female', 'freq_male']].\\\n",
    "plot(kind='bar', x='adjectives', ax=ax[1], rot=0)\n",
    "\n",
    "ax[0].set_title('Higher coefficient score')\n",
    "ax[1].set_title('Lower coefficient score')\n",
    "ax[0].set_ylabel('% biographies containing the adjective')\n",
    "ax[1].set_ylabel('% biographies containing the adjective')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint appearance of adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score_adj(df_f, df_m, words):\n",
    "    f_similarity = {}\n",
    "    m_similarity = {}\n",
    "    \n",
    "    fem_common_adj = df_f.withColumn('adjectives', explode(df_f.adjectives))\n",
    "    male_common_adj = df_m.withColumn('adjectives', explode(df_m.adjectives))\n",
    "    \n",
    "    for i in range(len(words)): \n",
    "        print(\"\\r Processing {} out of {}\".format(i+1, len(words)), end=\"\")\n",
    "        w1 = words[i]\n",
    "        f_w1 = set(fem_common_adj[fem_common_adj.adjectives == w1].select('id').dropDuplicates().collect())\n",
    "        m_w1 = set(male_common_adj[male_common_adj.adjectives == w1].select('id').dropDuplicates().collect())\n",
    "        \n",
    "        for j in range(i+1, len(words)):\n",
    "            w2 = words[j]\n",
    "            f_w2 = set(fem_common_adj[fem_common_adj.adjectives == w2].select('id').dropDuplicates().collect())\n",
    "            m_w2 = set(male_common_adj[male_common_adj.adjectives == w2].select('id').dropDuplicates().collect())\n",
    "        \n",
    "            f_similarity[(w1, w2)] = len(f_w1.intersection(f_w2))/len(f_w1.union(f_w2))\n",
    "            f_similarity[(w2, w1)] = f_similarity[(w1, w2)]\n",
    "            \n",
    "            m_similarity[(w1, w2)] = len(m_w1.intersection(m_w2))/len(m_w1.union(m_w2))\n",
    "            m_similarity[(w2, w1)] = m_similarity[(w1, w2)]\n",
    "    return f_similarity, m_similarity\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_adj = 10\n",
    "fem_sim, male_sim = similarity_score_adj(df_fem_model, df_male_model, \\\n",
    "                    df_coef.head(num_adj)['adjective'].tolist() + df_coef.tail(num_adj)['adjective'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df_coef.head(num_adj)['adjective'].tolist() + df_coef.tail(num_adj)['adjective'].tolist()\n",
    "\n",
    "f_sim = np.zeros((len(words),len(words)))\n",
    "m_sim = np.zeros((len(words),len(words)))\n",
    "\n",
    "for i in range(len(words)):\n",
    "    for j in range(i+1, len(words)):\n",
    "        f_sim[i,j] = fem_sim[(words[i], words[j])]\n",
    "        f_sim[j,i] = f_sim[i,j]\n",
    "        m_sim[i,j] = male_sim[(words[i], words[j])]\n",
    "        m_sim[j,i] = m_sim[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "sns.heatmap(f_sim, xticklabels=words, yticklabels=words, cmap='viridis', ax=ax[0])\n",
    "sns.heatmap(m_sim, xticklabels=words, yticklabels=words, cmap='viridis', ax=ax[1])\n",
    "\n",
    "ax[0].set_title('Common occurences Females')\n",
    "ax[1].set_title('Common occurences Males')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps \n",
    "\n",
    "- Validate our results by checking the ratio of the most correlated adjective to a gender (like beautiful for women), to whole dataset (how many female biographies contain that adjective)\n",
    "- Explore the source of the bias and the parameters that affect it\n",
    "- Explore biases among occupations \n",
    "- Implement the data story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🦄🦄🦄🦄"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
